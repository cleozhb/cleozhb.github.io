<!DOCTYPE html><html lang="en" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>CUDA概念理解以及犯过的错 | cleo札记</title><meta name="author" content="cleo"><meta name="copyright" content="cleo"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="首先要记录的就是这次改bug的过程，Program received signal CUDA_EXCEPTION_14, Warp Illegal Address.错误的原因是CUDA访问越界。要记住一个点__syncthreads()函数仅仅能够用于线程块内的线程同步，不能用于全局所有线程块的同步。我这次犯的错就是在一个核函数内部试图构造一个全局数组，然后接下来的操作用到此全局数组的值。">
<meta property="og:type" content="article">
<meta property="og:title" content="CUDA概念理解以及犯过的错">
<meta property="og:url" content="http://example.com/2018/09/16/CUDA%E6%A6%82%E5%BF%B5%E7%90%86%E8%A7%A3%E4%BB%A5%E5%8F%8A%E7%8A%AF%E8%BF%87%E7%9A%84%E9%94%99/index.html">
<meta property="og:site_name" content="cleo札记">
<meta property="og:description" content="首先要记录的就是这次改bug的过程，Program received signal CUDA_EXCEPTION_14, Warp Illegal Address.错误的原因是CUDA访问越界。要记住一个点__syncthreads()函数仅仅能够用于线程块内的线程同步，不能用于全局所有线程块的同步。我这次犯的错就是在一个核函数内部试图构造一个全局数组，然后接下来的操作用到此全局数组的值。">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="http://example.com/img/11111.jpg">
<meta property="article:published_time" content="2018-09-16T04:35:59.000Z">
<meta property="article:modified_time" content="2024-04-08T10:54:25.041Z">
<meta property="article:author" content="cleo">
<meta property="article:tag" content="CUDA">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://example.com/img/11111.jpg"><link rel="shortcut icon" href="/"><link rel="canonical" href="http://example.com/2018/09/16/CUDA%E6%A6%82%E5%BF%B5%E7%90%86%E8%A7%A3%E4%BB%A5%E5%8F%8A%E7%8A%AF%E8%BF%87%E7%9A%84%E9%94%99/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css"><script>
    (() => {
      
    const saveToLocal = {
      set: (key, value, ttl) => {
        if (!ttl) return
        const expiry = Date.now() + ttl * 86400000
        localStorage.setItem(key, JSON.stringify({ value, expiry }))
      },
      get: key => {
        const itemStr = localStorage.getItem(key)
        if (!itemStr) return undefined
        const { value, expiry } = JSON.parse(itemStr)
        if (Date.now() > expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return value
      }
    }

    window.btf = {
      saveToLocal,
      getScript: (url, attr = {}) => new Promise((resolve, reject) => {
        const script = document.createElement('script')
        script.src = url
        script.async = true
        Object.entries(attr).forEach(([key, val]) => script.setAttribute(key, val))
        script.onload = script.onreadystatechange = () => {
          if (!script.readyState || /loaded|complete/.test(script.readyState)) resolve()
        }
        script.onerror = reject
        document.head.appendChild(script)
      }),
      getCSS: (url, id) => new Promise((resolve, reject) => {
        const link = document.createElement('link')
        link.rel = 'stylesheet'
        link.href = url
        if (id) link.id = id
        link.onload = link.onreadystatechange = () => {
          if (!link.readyState || /loaded|complete/.test(link.readyState)) resolve()
        }
        link.onerror = reject
        document.head.appendChild(link)
      }),
      addGlobalFn: (key, fn, name = false, parent = window) => {
        if (!false && key.startsWith('pjax')) return
        const globalFn = parent.globalFn || {}
        globalFn[key] = globalFn[key] || {}
        globalFn[key][name || Object.keys(globalFn[key]).length] = fn
        parent.globalFn = globalFn
      }
    }
  
      
      const activateDarkMode = () => {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      const activateLightMode = () => {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }

      btf.activateDarkMode = activateDarkMode
      btf.activateLightMode = activateLightMode

      const theme = saveToLocal.get('theme')
    
          theme === 'dark' ? activateDarkMode() : theme === 'light' ? activateLightMode() : null
        
      
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        document.documentElement.classList.toggle('hide-aside', asideStatus === 'hide')
      }
    
      
    const detectApple = () => {
      if (/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)) {
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
  
    })()
  </script><script>const GLOBAL_CONFIG = {
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: undefined,
  highlight: {"plugin":"highlight.js","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":200,"highlightFullpage":false,"highlightMacStyle":false},
  copy: {
    success: 'Copy Successful',
    error: 'Copy Failed',
    noSupport: 'Browser Not Supported'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  dateSuffix: {
    just: 'Just now',
    min: 'minutes ago',
    hour: 'hours ago',
    day: 'days ago',
    month: 'months ago'
  },
  copyright: undefined,
  lightbox: 'null',
  Snackbar: undefined,
  infinitegrid: {
    js: 'https://cdn.jsdelivr.net/npm/@egjs/infinitegrid/dist/infinitegrid.min.js',
    buttonText: 'Load More'
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: false,
  },
  autoDarkmode: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'CUDA概念理解以及犯过的错',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: false,
  isShuoshuo: false
}</script><meta name="generator" content="Hexo 7.3.0"></head><body><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img text-center"><img src="/img/11111.jpg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="site-data text-center"><a href="/archives/"><div class="headline">Articles</div><div class="length-num">53</div></a><a href="/tags/"><div class="headline">Tags</div><div class="length-num">35</div></a><a href="/categories/"><div class="headline">Categories</div><div class="length-num">7</div></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> Categories</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg fixed" id="page-header" style="background-image: url(/img/pic11.png);"><nav id="nav"><span id="blog-info"><a class="nav-site-title" href="/"><img class="site-icon" src="/img/11111.jpg" alt="Logo"><span class="site-name">cleo札记</span></a><a class="nav-page-title" href="/"><span class="site-name">CUDA概念理解以及犯过的错</span></a></span><div id="menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> Categories</span></a></div></div><div id="toggle-menu"><span class="site-page"><i class="fas fa-bars fa-fw"></i></span></div></div></nav><div id="post-info"><h1 class="post-title">CUDA概念理解以及犯过的错</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">Created</span><time class="post-meta-date-created" datetime="2018-09-16T04:35:59.000Z" title="Created 2018-09-16 12:35:59">2018-09-16</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">Updated</span><time class="post-meta-date-updated" datetime="2024-04-08T10:54:25.041Z" title="Updated 2024-04-08 18:54:25">2024-04-08</time></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title=""><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">Post Views:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="container post-content" id="article-container"><p>首先要记录的就是这次改bug的过程，Program received signal CUDA_EXCEPTION_14, Warp Illegal Address.错误的原因是CUDA访问越界。要记住一个点__syncthreads()函数仅仅能够用于线程块内的线程同步，不能用于全局所有线程块的同步。我这次犯的错就是在一个核函数内部试图构造一个全局数组，然后接下来的操作用到此全局数组的值。</p>
<span id="more"></span>



<p>&#x2F;&#x2F;错误的写法</p>
<p><strong>global</strong> void ReLabelEachPixel(int* d_label, int* d_RootPos, int* d_IsRoot, int curPatchNum, int labelStart, int width, int task_height)</p>
<p>{</p>
<p>​    int x &#x3D; blockIdx.x * blockDim.x + threadIdx.x**;**</p>
<p>​    int y &#x3D; blockIdx.y * blockDim.y + threadIdx.y**;**</p>
<p>​    int gid &#x3D; x + y * width**;&#x2F;&#x2F;global 1D index;**</p>
<p>​    </p>
<p>​    if (gid &lt; curPatchNum)</p>
<p>​    {</p>
<p>​        d_IsRoot[d_RootPos[gid]] &#x3D; 1**;**</p>
<p>​    }   </p>
<p>​    __syncthreads()<strong>;</strong></p>
<p>​    &#x2F;&#x2F;判断哪些节点是根节点，是根节点的pixel不需要重标记</p>
<p>​    bool limits &#x3D; x &lt; width &amp;&amp; y &lt; task_height**;**</p>
<p>​    if (limits)</p>
<p>​    {</p>
<p>​        int center &#x3D; d_label[gid]<strong>;</strong></p>
<p>​        if(center!&#x3D; NO_USE_CLASS)</p>
<p>​        {</p>
<p>​            if(!d_IsRoot[gid])&#x2F;&#x2F;如果当前pixel不是根，更新其为根节点的值</p>
<p>​            {</p>
<p>​                d_label[gid] -&#x3D; labelStart**;**</p>
<p>​                d_label[gid] &#x3D; d_label[d_label[gid]]<strong>;</strong></p>
<p>​            }</p>
<p>​        }</p>
<p>​    }</p>
<p>}</p>
<p>在上面错误的版本中，在一个核函数内部构造全局数组，然后接下来的操作用到此全局数组的值，这两步中间用了__syncthreads()函数同步。这样的同步并不能保证d_IsRoot中所有线程块负责的像元都初始化完毕，所以会出错。</p>
<p>结论：__syncthreads()函数仅仅能够用于线程块内的线程同步，不能用于全局所有线程块的同步，所有线程块的同步必须用两个核函数来完成。两个核函数是串行执行的，相当于中间有个阻塞。正确的应该将上面的改为如下两个核函数。</p>
<p>`&#96;&#96;</p>
<p>&#x2F;&#x2F;正确的版本</p>
<p><strong>global</strong> void Set_d_IsRoot(int* d_RootPos, int* d_IsRoot, int curPatchNum, int width)</p>
<p>{</p>
<p>​    int x &#x3D; blockIdx.x * blockDim.x + threadIdx.x**;**</p>
<p>​    int y &#x3D; blockIdx.y * blockDim.y + threadIdx.y**;**</p>
<p>​    int gid &#x3D; x + y * width**;&#x2F;&#x2F;global 1D index;**</p>
<p>​    &#x2F;&#x2F;判断哪些节点是根节点，是根节点的pixel不需要重标记</p>
<p>​    if (gid &lt; curPatchNum)</p>
<p>​    {</p>
<p>​        d_IsRoot[d_RootPos[gid]] &#x3D; 1**;**</p>
<p>​    }   </p>
<p>}</p>
<p><strong>global</strong> void ReLabelEachPixel(int* d_label, int* d_IsRoot, int labelStart, int width, int task_height)</p>
<p>{</p>
<p>​    int x &#x3D; blockIdx.x * blockDim.x + threadIdx.x**;**</p>
<p>​    int y &#x3D; blockIdx.y * blockDim.y + threadIdx.y**;**</p>
<p>​    int gid &#x3D; x + y * width**;&#x2F;&#x2F;global 1D index;**</p>
<p>​    &#x2F;&#x2F;判断哪些节点是根节点，是根节点的pixel不需要重标记</p>
<p>​    bool limits &#x3D; x &lt; width &amp;&amp; y &lt; task_height**;**</p>
<p>​    if (limits)</p>
<p>​    {</p>
<p>​        int center &#x3D; d_label[gid]<strong>;</strong></p>
<p>​        if(center!&#x3D; NO_USE_CLASS)</p>
<p>​        {</p>
<p>​            if(!d_IsRoot[gid])&#x2F;&#x2F;如果当前pixel不是根，更新其为根节点的值</p>
<p>​            {</p>
<p>​                d_label[gid] -&#x3D; labelStart**;**</p>
<p>​                d_label[gid] &#x3D; d_label[d_label[gid]]<strong>;</strong></p>
<p>​            }</p>
<p>​        }</p>
<p>​    }</p>
<p>}</p>
<p>`&#96;&#96;</p>
<p>​    并行编程的中心思想是分而治之：将大问题划分为一些小问题，再把这些小问题交给相应的处理单元并行地进行处理。在   <em>CUDA</em>  中，这一思想便体现在  <em>Grid, Block, Thread</em>   等层次划分上。</p>
<p><strong>### CUDA执行模型</strong></p>
<p>一个<em>Thread</em>被执行过程：</p>
<p>​    <em>Grid</em>在<em>GPU</em>上启动；</p>
<p>​    <em>block</em>被分配到<em>SM</em>上；</p>
<p>​    <em>SM</em>把线程组织为<em>warp</em>；</p>
<p>​    <em>SM</em>调度执行<em>warp</em>；</p>
<p>​    执行结束后释放资源；</p>
<p>​    <em>block</em>继续被分配*….*</p>
<p>* sp : streaming processor 最基本的处理单元，最后具体的指令都是在sp上进行处理的，GPU进行并行计算也就是多个sp同时做处理。</p>
<p>* sm : streaming multiprocessor 多个sp加上一些其他的资源组成一个sm。其他的资源就是存储资源，共享内存，寄存器等</p>
<p>* warp:GPU执行程序时的调度单位，目前cuda的warp大小为32,在同一个warp 的线程，以不同的数据执行相同的指令</p>
<p><img src="/CUDA%E6%A6%82%E5%BF%B5%E7%90%86%E8%A7%A3%E4%BB%A5%E5%8F%8A%E7%8A%AF%E8%BF%87%E7%9A%84%E9%94%99/1.png"></p>
<p><img src="/CUDA%E6%A6%82%E5%BF%B5%E7%90%86%E8%A7%A3%E4%BB%A5%E5%8F%8A%E7%8A%AF%E8%BF%87%E7%9A%84%E9%94%99/2.png"></p>
<p>一个sm只会执行一个block中的warp，当一个block中的warp执行完，才会执行其他block中的warp。进行划分时，保证每个block中的warp比较合理，可以让sm交替执行里面的warp。此外，在分配block时，要根据GPU的sm个数，分配出合理的block数，让GPU的sm都利用起来，提高利用率。分配时，也要考虑到同一个线程block的资源问题，不要出现对应的资源不够。</p>
<p>GPU线程以网格（grid）的方式组织，而每个网格中又包含若干个线程块，在G80&#x2F;GT200系列中，每一个线程块最多可包含512个线程，Fermi架构中每个线程块支持高达1536个线程。同一线程块中的众多线程拥有相同的指令地址，不仅能够并行执行，而且能够通过共享存储器（Shared memory）和栅栏（barrier）实现块内通信。这样，同一网格内的不同块之间存在不需要通信的粗粒度并行，而一个块内的线程之间又形成了允许通信的细粒度并行。这些就是CUDA的关键特性：线程按照粗粒度的线程块和细粒度的线程两个层次进行组织、在细粒度并行的层次通过共享存储器和栅栏同步实现通信，这就是CUDA的双层线程模型。</p>
<p>​    在执行时，GPU的任务分配单元（global block scheduler）将网格分配到GPU芯片上。启动CUDA 内核时，需要将网格信息从CPU传输到GPU。任务分配单元根据这些信息将块分配到SM上。任务分配单元使用的是轮询策略：轮询查看SM是否还有足够的资源来执行新的块，如果有则给SM分配一个新的块，如果没有则查看下一个SM。决定能否分配的因素有：每个块使用的共享存储器数量，每个块使用的寄存器数量，以及其它的一些限制条件。任务分配单元在SM的任务分配中保持平衡，但是程序员可以通过更改块内线程数，每个线程使用的寄存器数和共享存储器数来隐式的控制，从而保证SM之间的任务均衡。任务以这种方式划分能够使程序获得了可扩展性：由于每个子问题都能在任意一个SM上运行，CUDA程序在核心数量不同的处理器上都能正常运行，这样就隐藏了硬件差异。</p>
<p>​    对于程序员来说，他们需要将任务划分为互不相干的粗粒度子问题(最好是易并行计算)，再将每个子问题划分为能够使用线程处理的问题。同一线程块中的线程开始于相同的指令地址，理论上能够以不同的分支执行。但实际上，在块内的分支因为SM构架的原因被大大限制了。内核函数实质上是以块为单位执行的。同一线程块中的线程需要SM中的共享存储器共享数据，因此它们必须在同一个SM中发射。线程块中的每一个线程被发射到一个SP上。任务分配单元可以为每个SM分配最多8个块。而SM中的线程调度单元又将分配到的块进行细分，将其中的线程组织成更小的结构，称为线程束（warp）。在CUDA中，warp对程序员来说是透明的，它的大小可能会随着硬件的发展发生变化，在当前版本的CUDA中，每个warp是由32个线程组成的。SM中一条指令的延迟最小为4个指令周期。8个SP采用了发射一次指令，执行4次的流水线结构。所以由32个线程组成的Warp是CUDA程序执行的最小单位，并且同一个warp是严格串行的，因此在warp内是无须同步的。在一个SM中可能同时有来自不同块的warp。当一个块中的warp在进行访存或者同步等高延迟操作时，另一个块可以占用SM中的计算资源。这样，在SM内就实现了简单的乱序执行。不同块之间的执行没有顺序，完全并行。无论是在一次只能处理一个线程块的GPU上,还是在一次能处理数十乃至上百个线程块的GPU上，这一模型都能很好的适用。</p>
<p>例如GTX760, 6SM， 192SP&#x2F;SM，一个SM一次执行一个Block，假设一个Warp含32个Thread,一个Block线程数量应该远远大于192(6warp)，为的是GPU执行长延时操作。（CUDA处理器需要高效地执行长延时操作，如果warp中的线程执行一个条指令需要等待前面启动的长延时操作的结果，那么不会选择执行该warp，而是选择执行另一个不用等待结果的驻留的warp，这样，如果有了多个warp准备执行，则总可以选择不产生延时的线程先执行，达到所谓的延时隐藏。）</p>
<p><img src="/CUDA%E6%A6%82%E5%BF%B5%E7%90%86%E8%A7%A3%E4%BB%A5%E5%8F%8A%E7%8A%AF%E8%BF%87%E7%9A%84%E9%94%99/3.png"></p>
<p>​    目前，某一时刻只能有一个内核函数正在执行，但是在Fermi架构中，这一限制已被解除。如果在一个内核访问数据时，另一个内核能够进行计算，则可以有效的提高设备的利用率。</p>
<p>​    每一个块内线程数应该首先是32的倍数，因为这样的话可以适应每一个warp包含32个线程的要求，每一个warp中串行执行，这就要求每一个线程中不可以有过多的循环或者需要的资源过多。但是每一个块中如果线程数过多，可能由于线程中参数过多带来存储器要求过大，从而使SM处理的效率更低。所以，在函数不是很复杂的情况下，可以适当的增加线程数目，线程中不要加入循环。在函数比较复杂的情况下，每一个块中分配32或是64个线程比较合适。每一个SM同时处理一个块，只有在粗粒度层面上以及细粒度层面上均达到平衡，才能使得GPU的利用到达最大。我用的显卡为GeForce GTX560 Ti，每一个网格中允许的最大块数位65535个，而每个块中的线程数为1024个，所以说粗粒度平衡对于我来说影响比较小，就细粒度来说，每一个块中的线程数以及每一个线程中的循环就变得至关重要了。</p>
<p><strong>### CUDA编程模型</strong></p>
<p>CUDA函数类型</p>
<p>* <strong>device</strong>     执行于Device，仅能从Device调用。限制，不能用&amp;取地址；不支持递归；不支持static variable；不支持可变长度参数</p>
<p>* <strong>global</strong>      void： 执行于Device，仅能从Host调用。此类函数必须返回void</p>
<p>* <strong>host</strong>         执行于Host，仅能从Host调用，是函数的默认类型 </p>
<p>thread,block,grid是CUDA编程中的概念，用来组织GPU线程。在启动CUDA核函数时要指定gridsize和blocksize。假设有如下线程块配置：</p>
<p> dim3 gridsize(2,2)<strong>;</strong></p>
<p>  dim3 blocksize(4,4)<strong>;</strong></p>
<p>grid中的blockidx序号标注情况为</p>
<p>​                                                                   <img src="/CUDA%E6%A6%82%E5%BF%B5%E7%90%86%E8%A7%A3%E4%BB%A5%E5%8F%8A%E7%8A%AF%E8%BF%87%E7%9A%84%E9%94%99/4.png"></p>
<p>block中的threadidx序号标注情况</p>
<p>​                                                      <img src="/CUDA%E6%A6%82%E5%BF%B5%E7%90%86%E8%A7%A3%E4%BB%A5%E5%8F%8A%E7%8A%AF%E8%BF%87%E7%9A%84%E9%94%99/5.png"></p>
<p><img src="/CUDA%E6%A6%82%E5%BF%B5%E7%90%86%E8%A7%A3%E4%BB%A5%E5%8F%8A%E7%8A%AF%E8%BF%87%E7%9A%84%E9%94%99/6.png"></p>
<p><img src="/CUDA%E6%A6%82%E5%BF%B5%E7%90%86%E8%A7%A3%E4%BB%A5%E5%8F%8A%E7%8A%AF%E8%BF%87%E7%9A%84%E9%94%99/7.png"></p>
<p><img src="/CUDA%E6%A6%82%E5%BF%B5%E7%90%86%E8%A7%A3%E4%BB%A5%E5%8F%8A%E7%8A%AF%E8%BF%87%E7%9A%84%E9%94%99/8.png"></p>
<p>一个一维的block（此处只有x维度上存在16个线程）。所以，內建变量只有一个在起作用，就是threadIdx.x，它的范围是[0,15]。因此，我们在计算线程索引是，只用这个內建变量就行了（其他的为0，写了也不起作用）</p>
<p><img src="/CUDA%E6%A6%82%E5%BF%B5%E7%90%86%E8%A7%A3%E4%BB%A5%E5%8F%8A%E7%8A%AF%E8%BF%87%E7%9A%84%E9%94%99/9.png"></p>
<p>这个线程格只有一个一维的线程块，该线程块内的线程是二维的</p>
<p><img src="/CUDA%E6%A6%82%E5%BF%B5%E7%90%86%E8%A7%A3%E4%BB%A5%E5%8F%8A%E7%8A%AF%E8%BF%87%E7%9A%84%E9%94%99/10.png"></p>
<p><img src="/CUDA%E6%A6%82%E5%BF%B5%E7%90%86%E8%A7%A3%E4%BB%A5%E5%8F%8A%E7%8A%AF%E8%BF%87%E7%9A%84%E9%94%99/11.png"></p>
<p>一个grid和16个block，每个block都是一维</p>
<p><img src="/CUDA%E6%A6%82%E5%BF%B5%E7%90%86%E8%A7%A3%E4%BB%A5%E5%8F%8A%E7%8A%AF%E8%BF%87%E7%9A%84%E9%94%99/12.png"></p>
<p><img src="/CUDA%E6%A6%82%E5%BF%B5%E7%90%86%E8%A7%A3%E4%BB%A5%E5%8F%8A%E7%8A%AF%E8%BF%87%E7%9A%84%E9%94%99/13.png"></p>
<p><img src="/CUDA%E6%A6%82%E5%BF%B5%E7%90%86%E8%A7%A3%E4%BB%A5%E5%8F%8A%E7%8A%AF%E8%BF%87%E7%9A%84%E9%94%99/14.png"></p>
<p><strong>### CUDA内存模型</strong></p>
<p>每个 thread都有自己的一份 register 和 local memory的空间。一组thread构成一个 block，这些thread则共享有一份shared memory。__syncthreads()可以同步一个Block内的所有线程，不同Block内的Thread不能同步。此外，所有的 thread(包括不同 block 的 thread)都共享一份global memory、constant memory、和 texture memory。不同的 grid则有各自的 global memory、constant memory和 texture memory。cudaMalloc和cudaFree用于内存分配及释放，它们分配的是global memory，cudaMemcpy用于Hose-Device数据交换。</p>
<p><img src="/CUDA%E6%A6%82%E5%BF%B5%E7%90%86%E8%A7%A3%E4%BB%A5%E5%8F%8A%E7%8A%AF%E8%BF%87%E7%9A%84%E9%94%99/15.png"></p>
<p><strong>### CUDA调试</strong></p>
<p><img src="/CUDA%E6%A6%82%E5%BF%B5%E7%90%86%E8%A7%A3%E4%BB%A5%E5%8F%8A%E7%8A%AF%E8%BF%87%E7%9A%84%E9%94%99/16.png"></p>
<p><strong>### 参考</strong></p>
<p>CUDA学习笔记：<a target="_blank" rel="noopener" href="http://luofl1992.is-programmer.com/posts/38830.html">http://luofl1992.is-programmer.com/posts/38830.html</a></p>
<p>CUDA概念理解：<a target="_blank" rel="noopener" href="https://blog.csdn.net/lg1259156776/article/details/52804840">https://blog.csdn.net/lg1259156776/article/details/52804840</a></p>
<p>grid,block,thread的关系及计算：<a target="_blank" rel="noopener" href="https://blog.csdn.net/hujingshuang/article/details/53097222">https://blog.csdn.net/hujingshuang/article/details/53097222</a></p>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta"><i class="fas fa-circle-user fa-fw"></i>Author: </span><span class="post-copyright-info"><a href="http://example.com">cleo</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta"><i class="fas fa-square-arrow-up-right fa-fw"></i>Link: </span><span class="post-copyright-info"><a href="http://example.com/2018/09/16/CUDA%E6%A6%82%E5%BF%B5%E7%90%86%E8%A7%A3%E4%BB%A5%E5%8F%8A%E7%8A%AF%E8%BF%87%E7%9A%84%E9%94%99/">http://example.com/2018/09/16/CUDA%E6%A6%82%E5%BF%B5%E7%90%86%E8%A7%A3%E4%BB%A5%E5%8F%8A%E7%8A%AF%E8%BF%87%E7%9A%84%E9%94%99/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta"><i class="fas fa-circle-exclamation fa-fw"></i>Copyright Notice: </span><span class="post-copyright-info">All articles on this blog are licensed under <a target="_blank" rel="noopener" href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0</a> unless otherwise stated.</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/CUDA/">CUDA</a></div><div class="post-share"><div class="social-share" data-image="/img/11111.jpg" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><a class="pagination-related" href="/2018/10/11/MPI%E5%AE%9E%E7%8E%B0manager-worker%E6%A8%A1%E5%BC%8F/" title="MPI实现manager-worker模式"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info"><div class="info-1"><div class="info-item-1">Previous</div><div class="info-item-2">MPI实现manager-worker模式</div></div><div class="info-2"><div class="info-item-1">...</div></div></div></a><a class="pagination-related" href="/2018/09/12/%E8%AE%B0%E5%AE%9E%E9%AA%8C%E5%AE%A4code-review/" title="记实验室code review"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-right"><div class="info-1"><div class="info-item-1">Next</div><div class="info-item-2">记实验室code review</div></div><div class="info-2"><div class="info-item-1">2018年9月11号晚上，实验室在姚老师的领导下进行了第一次code review。姚老师结合同学的代码讲了很多与编码规范相关的东西。现在记录如下。 核心思想是代码逻辑清晰可读，只读主函数就可以看懂程序的逻辑，整个程序的执行步骤先做什么后做什么，有必要的注释，所有变量命名和函数名具有自注释性。  整个程序只有在主函数中可以容忍出现megic number并要求用宏定义 在所有的文件中不可以出现绝对路径（除了主函数） 在VS下编码的时候，将库拷贝到当前目录，用相对路径引入库，以便于代码移植，如果用绝对路径会导致这个工程在别的机器上跑的时候全部要重新配置一遍所有的库 控制代码的粒度和可复用性     函数的命名与变量的命名要有明显的区别，严格按照驼峰命名法，否则你只看名字是分不清是函数还是变量的 注意返回值，函数的返回值不能乱写。尤其是在linux下，函数返回负值说明执行失败，返回正值说明执行成功. 容灾性设计：当函数出错了怎么办，内存申请不成功怎么办 在头文件中，不要用命名空间using...</div></div></div></a></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>Related Articles</span></div><div class="relatedPosts-list"><a class="pagination-related" href="/2019/01/23/Array-2D-CUDA%E4%BD%BF%E7%94%A8CUDA%E6%89%A9%E5%B1%95C-%E6%A8%A1%E6%9D%BF%E5%BA%93/" title="Array_2D_CUDA使用CUDA扩展C++模板库"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2019-01-23</div><div class="info-item-2">Array_2D_CUDA使用CUDA扩展C++模板库</div></div><div class="info-2"><div class="info-item-1">...</div></div></div></a><a class="pagination-related" href="/2018/05/17/CUDA%E6%80%A7%E8%83%BD%E6%8C%87%E6%A0%87/" title="CUDA性能指标"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2018-05-17</div><div class="info-item-2">CUDA性能指标</div></div><div class="info-2"><div class="info-item-1">共享内存被分配在SM上的常驻线程块中，寄存器在线程中被分配。寄存器和共享内存是SM中的稀缺资源。CUDA将这些资源分配到SM中的所有常驻线程里。      参数 指令    观察线程束分化 nvprof –metrics branch_efficiency   获得分支和分化分支的事件计数器 nvprof –events branch,divergent_branch   检测活跃的线程束(一个内核的可实现占用率) nvprof –metrics achieved_occupacy   检测内核的内存读取效率 nvprof –metrics gld_throughput   检测全局加载效率 nvprof –metrics gld_efficiency   查看每个线程束上执行指令数量的平均值 nvprof –metrics inst_per_warp   查看因为同步占用的时间 nvprof –metrics stall_sync   检测内存加载&#x2F;存储效率指标 nvprof –metrics...</div></div></div></a><a class="pagination-related" href="/2018/01/21/Dijkstras%E6%9C%80%E7%9F%AD%E8%B7%AF%E5%BE%84%E7%AE%97%E6%B3%95%E7%9A%84MPI%E5%92%8CCUDA%E5%AE%9E%E7%8E%B0/" title="Dijkstras最短路径算法的MPI和CUDA实现"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2018-01-21</div><div class="info-item-2">Dijkstras最短路径算法的MPI和CUDA实现</div></div><div class="info-2"><div class="info-item-1">Dijkstras最短路径算法的MPI和CUDA实现 主要内容   dijkstra串行算法 算法并行性分析 MPI的dijkstra实现 CUDA的dijkstra实现 并行效率分析    dijkstra串行算法串行算法核心思想 引入一个辅助向量D，它的每个分量D[i]为源顶点v到其他顶点v[i]的路径长度。初始态为：如有从v到vi的路径，则D[i]为弧[v,vi]的权值；否则D[i]为无穷大。显然D[j] &#x3D; min{D[i]}为顶点v出发到其他顶点的一条最短路径的长度，其路径为（v，vj）。下一条最短路径长度要么是源顶点v直接到某一顶点vk的长度，即{v，vk}。要么是源顶点v经过顶点vj到某一顶点的长度，即{v，vj，vk}。假设S为已经求得最短路径的顶点的集合，下一条最短路径（设其终点为x），要么是弧{v， vx}，要么为中间只经过S中顶点而最后到达终点X的路径。在一般情况下，下一条最短路径的长度为：D[j] &#x3D; min{D[i] | vi 属于 V-S} 其中V为图顶点的集合， D[i]为弧{v， vi}的权值，或者为D[k]和弧{vk，...</div></div></div></a><a class="pagination-related" href="/2018/10/22/MPI-CUDA%E6%B7%B7%E5%90%88%E7%BC%96%E7%A8%8B-Makefile%E6%96%87%E4%BB%B6%E5%86%99%E6%B3%95/" title="MPI+CUDA混合编程 Makefile文件写法"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2018-10-22</div><div class="info-item-2">MPI+CUDA混合编程 Makefile文件写法</div></div><div class="info-2"><div class="info-item-1">CUDA代码与c++代码分开时Makefile文件的写法用网上找的一个例子作为参考，主要记录Makefile文件的写法总的来说就是要用nvcc编译.cu文件，生成.o文件;然后用mpic++编译.cpp文件，生成.o文件;最后用mpic++将这两个.o文件连接起来，生成可执行文件。在控制台中依次键入下面的命令，可以生成可执行文件main。 123# nvcc -c test_cuda.cu# mpic++ -c test.cpp# mpic++ -o main test.o test_cuda.o  -L /usr/local/cuda-8.0/lib64 -lcudart    完整的Makefile文件写法如下：几个要注意的点：  弄清楚CUDA和MPI的环境变量。如果不知道，可以用which 命令查看。 最后一行，生成可执行文件的那一行，依赖的库放在最后，将目标文件写在中间，否则在有些机器上会报错。 学到了一个函数，fseek， 可以将数组写入到文件指定的位置;  123456789101112131415161718192021CUDA_INSTALL_PATH =...</div></div></div></a><a class="pagination-related" href="/2018/09/02/NVIDIA-parallel-computing-5/" title="NVIDIA parallel computing-5"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2018-09-02</div><div class="info-item-2">NVIDIA parallel computing-5</div></div><div class="info-2"><div class="info-item-1">Lesson5 optimizing GPU programs picking good algorithms 选择时间复杂度低的算法 basic principles for efficiency 提高效率的基本原则 arch-specific detailed optimization 优化架构上的细节 Optimization at instruction level...</div></div></div></a><a class="pagination-related" href="/2019/04/07/%E5%A4%9A%E8%8A%82%E7%82%B9MPI-CUDA%E7%9A%84%E7%A8%8B%E5%BA%8F%E4%B8%ADGPU%E4%B8%8E%E8%BF%9B%E7%A8%8B%E7%9A%84%E7%BB%91%E5%AE%9A/" title="多节点MPI+CUDA的程序中GPU与进程的绑定"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2019-04-07</div><div class="info-item-2">多节点MPI+CUDA的程序中GPU与进程的绑定</div></div><div class="info-2"><div class="info-item-1">问题描述GPU是提升性能的强大工具，所以我们希望能够利用多GPU提升程序的效率，这样就可以实现MPI进程+CUDA轻量级线程的两层并行。NVIDIA的SLI(Scalable Link...</div></div></div></a></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info text-center"><div class="avatar-img"><img src="/img/11111.jpg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info-name">cleo</div><div class="author-info-description">From zero to hero</div><div class="site-data"><a href="/archives/"><div class="headline">Articles</div><div class="length-num">53</div></a><a href="/tags/"><div class="headline">Tags</div><div class="length-num">35</div></a><a href="/categories/"><div class="headline">Categories</div><div class="length-num">7</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/xxxxxx"><i class="fab fa-github"></i><span>Follow Me</span></a></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>Announcement</span></div><div class="announcement_content">This is my Blog</div></div><div class="sticky_layout"><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>Recent Posts</span></div><div class="aside-list"><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2024/11/10/DDIA%E7%AC%AC%E5%85%AD%E7%AB%A0%EF%BC%9A%E5%88%86%E5%8C%BA/" title="DDIA第六章：分区">DDIA第六章：分区</a><time datetime="2024-11-09T16:43:50.000Z" title="Created 2024-11-10 00:43:50">2024-11-10</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2024/11/09/%E5%BE%AE%E6%9C%8D%E5%8A%A1%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1%E7%9A%84%E6%80%9D%E8%80%83%E2%80%94%E2%80%94%E8%85%BE%E8%AE%AF%E8%AF%BE%E5%A0%82/" title="微服务架构设计的思考——腾讯课堂">微服务架构设计的思考——腾讯课堂</a><time datetime="2024-11-09T15:43:28.000Z" title="Created 2024-11-09 23:43:28">2024-11-09</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2024/04/08/%E8%AE%BE%E8%AE%A1%E4%B8%80%E4%B8%AA%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F%E4%B8%AD%E7%9A%84%E5%94%AF%E4%B8%80ID%E7%94%9F%E6%88%90%E5%99%A8/" title="设计一个分布式系统中的唯一ID生成器">设计一个分布式系统中的唯一ID生成器</a><time datetime="2024-04-08T13:55:11.000Z" title="Created 2024-04-08 21:55:11">2024-04-08</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2019/05/06/STL-sort%E5%87%BD%E6%95%B0%E5%AE%9E%E7%8E%B0%E8%AF%A6%E8%A7%A3/" title="STL sort函数实现详解">STL sort函数实现详解</a><time datetime="2019-05-06T07:39:25.000Z" title="Created 2019-05-06 15:39:25">2019-05-06</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2019/04/28/%E6%B5%85%E8%B0%88%E5%A4%9A%E8%8A%82%E7%82%B9CPU-GPU%E5%8D%8F%E5%90%8C%E8%AE%A1%E7%AE%97%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%E6%80%A7%E8%AE%BE%E8%AE%A1/" title="多节点CPU+GPU协同计算负载均衡">多节点CPU+GPU协同计算负载均衡</a><time datetime="2019-04-28T12:15:10.000Z" title="Created 2019-04-28 20:15:10">2019-04-28</time></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2019 - 2024 By cleo</div><div class="framework-info"><span>Framework </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>Theme </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="Reading Mode"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="Toggle Between Light and Dark Mode"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="Toggle Between Single-column and Double-column"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="Settings"><i class="fas fa-cog fa-spin"></i></button><button id="go-up" type="button" title="Back to Top"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><div class="js-pjax"></div><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></body></html>