<!DOCTYPE html><html lang="en" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>高性能CUDA应用设计与开发——读书笔记（第四章） | cleo札记</title><meta name="author" content="cleo"><meta name="copyright" content="cleo"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="第四章：CUDA执行模型 主要内容   CUDA如何在保持扩展性的前提下表达并行计算 Warp与Half-warp的含义与重要性 调度、warp分歧以及GPU是SIMT架构的原因">
<meta property="og:type" content="article">
<meta property="og:title" content="高性能CUDA应用设计与开发——读书笔记（第四章）">
<meta property="og:url" content="http://example.com/2018/01/15/%E9%AB%98%E6%80%A7%E8%83%BDCUDA%E5%BA%94%E7%94%A8%E8%AE%BE%E8%AE%A1%E4%B8%8E%E5%BC%80%E5%8F%91%E2%80%94%E2%80%94%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0%EF%BC%88%E7%AC%AC%E5%9B%9B%E7%AB%A0%EF%BC%89/index.html">
<meta property="og:site_name" content="cleo札记">
<meta property="og:description" content="第四章：CUDA执行模型 主要内容   CUDA如何在保持扩展性的前提下表达并行计算 Warp与Half-warp的含义与重要性 调度、warp分歧以及GPU是SIMT架构的原因">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="http://example.com/img/11111.jpg">
<meta property="article:published_time" content="2018-01-15T12:07:45.000Z">
<meta property="article:modified_time" content="2024-04-07T11:37:25.839Z">
<meta property="article:author" content="cleo">
<meta property="article:tag" content="CUDA">
<meta property="article:tag" content="高性能计算">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://example.com/img/11111.jpg"><link rel="shortcut icon" href="/"><link rel="canonical" href="http://example.com/2018/01/15/%E9%AB%98%E6%80%A7%E8%83%BDCUDA%E5%BA%94%E7%94%A8%E8%AE%BE%E8%AE%A1%E4%B8%8E%E5%BC%80%E5%8F%91%E2%80%94%E2%80%94%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0%EF%BC%88%E7%AC%AC%E5%9B%9B%E7%AB%A0%EF%BC%89/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css"><script>
    (() => {
      
    const saveToLocal = {
      set: (key, value, ttl) => {
        if (!ttl) return
        const expiry = Date.now() + ttl * 86400000
        localStorage.setItem(key, JSON.stringify({ value, expiry }))
      },
      get: key => {
        const itemStr = localStorage.getItem(key)
        if (!itemStr) return undefined
        const { value, expiry } = JSON.parse(itemStr)
        if (Date.now() > expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return value
      }
    }

    window.btf = {
      saveToLocal,
      getScript: (url, attr = {}) => new Promise((resolve, reject) => {
        const script = document.createElement('script')
        script.src = url
        script.async = true
        Object.entries(attr).forEach(([key, val]) => script.setAttribute(key, val))
        script.onload = script.onreadystatechange = () => {
          if (!script.readyState || /loaded|complete/.test(script.readyState)) resolve()
        }
        script.onerror = reject
        document.head.appendChild(script)
      }),
      getCSS: (url, id) => new Promise((resolve, reject) => {
        const link = document.createElement('link')
        link.rel = 'stylesheet'
        link.href = url
        if (id) link.id = id
        link.onload = link.onreadystatechange = () => {
          if (!link.readyState || /loaded|complete/.test(link.readyState)) resolve()
        }
        link.onerror = reject
        document.head.appendChild(link)
      }),
      addGlobalFn: (key, fn, name = false, parent = window) => {
        if (!false && key.startsWith('pjax')) return
        const globalFn = parent.globalFn || {}
        globalFn[key] = globalFn[key] || {}
        globalFn[key][name || Object.keys(globalFn[key]).length] = fn
        parent.globalFn = globalFn
      }
    }
  
      
      const activateDarkMode = () => {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      const activateLightMode = () => {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }

      btf.activateDarkMode = activateDarkMode
      btf.activateLightMode = activateLightMode

      const theme = saveToLocal.get('theme')
    
          theme === 'dark' ? activateDarkMode() : theme === 'light' ? activateLightMode() : null
        
      
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        document.documentElement.classList.toggle('hide-aside', asideStatus === 'hide')
      }
    
      
    const detectApple = () => {
      if (/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)) {
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
  
    })()
  </script><script>const GLOBAL_CONFIG = {
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: undefined,
  highlight: {"plugin":"highlight.js","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":200,"highlightFullpage":false,"highlightMacStyle":false},
  copy: {
    success: 'Copy Successful',
    error: 'Copy Failed',
    noSupport: 'Browser Not Supported'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  dateSuffix: {
    just: 'Just now',
    min: 'minutes ago',
    hour: 'hours ago',
    day: 'days ago',
    month: 'months ago'
  },
  copyright: undefined,
  lightbox: 'null',
  Snackbar: undefined,
  infinitegrid: {
    js: 'https://cdn.jsdelivr.net/npm/@egjs/infinitegrid/dist/infinitegrid.min.js',
    buttonText: 'Load More'
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: false,
  },
  autoDarkmode: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: '高性能CUDA应用设计与开发——读书笔记（第四章）',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  isShuoshuo: false
}</script><meta name="generator" content="Hexo 7.3.0"></head><body><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img text-center"><img src="/img/11111.jpg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="site-data text-center"><a href="/archives/"><div class="headline">Articles</div><div class="length-num">53</div></a><a href="/tags/"><div class="headline">Tags</div><div class="length-num">35</div></a><a href="/categories/"><div class="headline">Categories</div><div class="length-num">7</div></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> Categories</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg fixed" id="page-header" style="background-image: url(/img/pic11.png);"><nav id="nav"><span id="blog-info"><a class="nav-site-title" href="/"><img class="site-icon" src="/img/11111.jpg" alt="Logo"><span class="site-name">cleo札记</span></a><a class="nav-page-title" href="/"><span class="site-name">高性能CUDA应用设计与开发——读书笔记（第四章）</span></a></span><div id="menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> Categories</span></a></div></div><div id="toggle-menu"><span class="site-page"><i class="fas fa-bars fa-fw"></i></span></div></div></nav><div id="post-info"><h1 class="post-title">高性能CUDA应用设计与开发——读书笔记（第四章）</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">Created</span><time class="post-meta-date-created" datetime="2018-01-15T12:07:45.000Z" title="Created 2018-01-15 20:07:45">2018-01-15</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">Updated</span><time class="post-meta-date-updated" datetime="2024-04-07T11:37:25.839Z" title="Updated 2024-04-07 19:37:25">2024-04-07</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/">读书笔记</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title=""><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">Post Views:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="container post-content" id="article-container"><h2 id="第四章：CUDA执行模型"><a href="#第四章：CUDA执行模型" class="headerlink" title="第四章：CUDA执行模型"></a>第四章：CUDA执行模型</h2><blockquote>
<p>主要内容</p>
</blockquote>
<ul>
<li>CUDA如何在保持扩展性的前提下表达并行计算</li>
<li>Warp与Half-warp的含义与重要性</li>
<li>调度、warp分歧以及GPU是SIMT架构的原因</li>
</ul>
<span id="more"></span>

<h3 id="线程角度的GPU编程"><a href="#线程角度的GPU编程" class="headerlink" title="线程角度的GPU编程"></a>线程角度的GPU编程</h3><p>CUDA性能与扩展性的本质来自于其可以将计算分割成固定大小的线程块的执行结构。这些线程块实现了GPU上大规模并行硬件之间的映射.GPU硬件的大规模并行是通过重复设置多个相同的通用构件块(流多处理器)来实现的。流多处理器的数量一定程度上决定了GPU的价格和性能。线程块的软件抽象将Kernel函数的一个自然映射转换到GPU上任意数量的流多处理器上。一个流多处理器可以调度执行一个或多个线程块。能调度线程块的数量仅仅由设备的性能所决定。也就是说每个流多处理器分配线程块的数量取决于一个流多处理器中最多能常驻的线程与线程块数量。</p>
<ul>
<li>这种映射可以透明的扩展到任意数量的流多处理器上；</li>
<li>对流多处理器的位置没有限制(可以在多个设备上进行扩展)；</li>
<li>能够将执行中的Kernel与用户参数广播给硬件；并行广播是扩展性最强、速度最快的通信机制，能将数据移动到大量的处理单元上；</li>
</ul>
<p>一个Block内的所有线程都会在一个流多处理器上执行，GPU设计者在流多处理器内部用共享内存在实现数据共享。这种方式避免了多核处理器中常出现的缓存不一致问题。确保缓存中的所有变量处于最新状态。</p>
<p>只要处于不同的流中，多个Kernel函数就可以在同一个GPU上同时执行。Kernel函数按照其发射顺序执行，只要前一个待执行的Kernel函数的所有线程都得到调度，且还有剩余的资源，就可以调度下一个Kernel函数。每个流多处理器独立调用内部资源、处理核心及其他执行单元，来执行为其分配的线程块内的线程。每个流多处理器执行相同的指令，处理不同的数据。</p>
<h3 id="性能角度的GPU编程"><a href="#性能角度的GPU编程" class="headerlink" title="性能角度的GPU编程"></a><a target="_blank" rel="noopener" href="http://blog.163.com/wujiaxing009@126/blog/static/71988399201701224540201/">性能角度的GPU编程</a></h3><p>以一个Warp或者半个Warp内部SIMD线程的数量为单位进行考虑。大多数GPU上一个Warp含有32个SIMD线程。Warp是流多处理器内部的基本调度单元。<br>使用基于线程块的无耦合全局与局部调度机制有很多优势：</p>
<ul>
<li>全局调度器必须监控的只有活动状态的流多处理器；</li>
<li>每个流多处理器调度一个线程块降低了线程资源分配的复杂度以及流多处理器内线程间的通信，以可扩展的方式对Kernel进行分割，流多处理器升值全局调度器无需知道其他流多处理器中在进行什么工作。</li>
</ul>
<p><strong>warp的执行</strong>：每周期将一个warp的1条指令或者可以双发射的两条指令（scheduler）发射到流处理器sp(stream prossor)和其他的执行单元上，其中，并不一定将32个sp一组安排，同时，一个warp也并不是从开始到结束总在相同的32个sp上执行。</p>
<p>Warp内各个条件子句分支之间是串行执行的，所以条件子句导致执行速度降低2倍，N层嵌套分支会使得执行速度降低2的N次方。任何流控制指令（if\switch\do\for\while）都会导致线程分歧，线程分歧时会顺序执行每个分支路径，禁用不在此路径上的线程，直到所有路径完成，线程再重新汇合到同一执行路径。</p>
<p>![warp divergence](.&#x2F;高性能CUDA应用设计与开发——读书笔记（第四章）&#x2F;warp divergency.PNG)</p>
<p>主要有以下3种情况：</p>
<ul>
<li>如果一个warp的32个线程都只满足同一个分支，这是所谓的“分支按warp对齐”的形式，此时分支基本不影响执行效率。</li>
<li>如果一个warp的32个线程分别满足多个分支，那么不满足当前分支的线程可能会采用插入等待或者假执行（跟着一起算，但是不保留结果）的方式，束内的每个线程都会对每个分支进行判定，如果判定满足，就会执行分支内的代码，如果不满足，线程会暂停等到其他线程执行完成，然后再一起执行下一步。总的运行时间是多个运行分支的时间之和，以及显然每次都有些线程不干活或者干无用功。</li>
<li>因为最小的执行单位就是warp，所以如果warp内不同线程的循环次数不同，那么这也是一种分支情况，并且时间是循环次数最多的那个线程所花费的时间。</li>
</ul>
<p>CPU有复杂的硬件设计可以很好的做分支预测，即预测应用程序会走哪个path分支。如果预测正确，那么CPU只会有很小的消耗。和CPU对比来说，GPU就没那么复杂的分支预测了。因为所有同一个warp中的thread必须执行相同的指令，那么如果这些线程在遇到控制流语句时，如果进入不同的分支，那么同一时刻除了正在执行的分支外，其余分支都被阻塞了，十分影响性能。这类问题就是warp divergence。注意，warp divergence问题只会发生在同一个warp中。</p>
<h4 id="分支预测"><a href="#分支预测" class="headerlink" title="分支预测"></a><a target="_blank" rel="noopener" href="http://blog.csdn.net/rrrfff/article/details/44993467">分支预测</a></h4><p>分支预测（Branch Prediction）是现代处理器用来提高CPU执行速度的一种手段, 其对程序的分支流程进行预测, 然后预先读取其中一个分支的指令并解码来减少等待译码器的时间.维基百科上对此的解释是”a strategy in computer architecture design for mitigating the costs usually associated with conditional branches, particularly branches to short sections of code.”</p>
<p>分支预测的错误并不会导致结果的错误，而只是导致流水线的停顿，如果能够保持较高的预测准确率，分支预测就能提高流水线的性能, 换言之, 如果在软件开发过程中, 能够考虑这一特性, 减少甚至移除条件分支(值得一提的是, 条件转移不需要预测, 因此条件转移也远没有产生错误分支的性能代价大), 能一定程度上提供程序的整体效率.</p>
<p>下面是几种常见的优化策略:</p>
<ol>
<li>避免在循环中嵌套条件分支. 如果可能,将分支移到外部, 使用多个子循环.</li>
</ol>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">do </span><br><span class="line">&#123;</span><br><span class="line">    if (condition_1)&#123;</span><br><span class="line">        //branch_1</span><br><span class="line">    &#125; else if (condition_2)&#123;</span><br><span class="line">        //branch_2</span><br><span class="line">    &#125; else &#123;</span><br><span class="line">        //branch_3</span><br><span class="line">    &#125; //if</span><br><span class="line">&#125; while (true);</span><br><span class="line"></span><br><span class="line">//改进版本</span><br><span class="line">if (condition_1) &#123;</span><br><span class="line">    do &#123;</span><br><span class="line">        //branch_1</span><br><span class="line">    &#125; while (true);</span><br><span class="line">&#125; else if (condition_2) &#123;</span><br><span class="line">    do &#123;</span><br><span class="line">        //branch_2</span><br><span class="line">    &#125; while (true);</span><br><span class="line">&#125; else &#123;</span><br><span class="line">    do &#123;</span><br><span class="line">        //branch_3</span><br><span class="line">    &#125; while (true);</span><br><span class="line">&#125; //if</span><br></pre></td></tr></table></figure>

<ol start="2">
<li>合并分支条件.在某种情况下可以大大降低产生错误分支预测的概率.</li>
</ol>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">if (condition_1 == 0 || condition_2 == 0 || </span><br><span class="line">    condition_3 == 0) &#123;</span><br><span class="line">    //branch</span><br><span class="line">&#125; //if</span><br><span class="line"></span><br><span class="line">//改进版本:</span><br><span class="line">if ((condition_1 | condition_2 | condition_3) == 0) &#123;</span><br><span class="line">    //branch</span><br><span class="line">&#125; //if</span><br></pre></td></tr></table></figure>

<ol start="3">
<li>移除明显的条件分支, 将执行概率大的条件分支移前.这一条不仅仅有助于规避错误分支带来的性能惩罚, 还减少了不必要的检测分支条件消耗的CPU时钟周期.</li>
</ol>
<p>编译器只有在条件分支控制的指令数小于或等于一个确定的阈值时，才会使用呢预测指令替换分支指令。如果编译器腿短条件会产生许多有分歧的warp，阈值为7，否则阈值为4.如果分支中的代码过长，nvcc编译器会插入代码执行warp表决。来查询warp所有线程是否都执行相同的分支。如果warp中所有线程都表决相同的执行分支，说明性能没有下降。</p>
<h4 id="避免warp分歧-Warp-Divergence-的准则"><a href="#避免warp分歧-Warp-Divergence-的准则" class="headerlink" title="避免warp分歧(Warp Divergence)的准则"></a>避免warp分歧(Warp Divergence)的准则</h4><p>warp分歧有时候不可避免，尤其是树、图等不规则的数据结构。<br>下面是几种常见的避免准则：</p>
<ol>
<li>使用不同的算法重新规划问题，避免引起warp分歧，或者以编译器能够降低或消除warp分歧的方式表示问题。</li>
<li>将不同计算代价的任务分别列表，每个列表使用一个独立的kernel函数。最好将大量工作在计算代价低的kernel中完成，一些计算代价高的任务也可以在CPU上完成。</li>
<li>将计算任务排序并分块，块的大小为半个warp的整数倍。</li>
<li>如果可以，使用异步kernel执行方式，充分利用SIMT的执行模型。</li>
<li>使用主处理器来处理部分任务会造成GPU负载不均衡。</li>
</ol>
<h4 id="warp的资源划分-resource-partition"><a href="#warp的资源划分-resource-partition" class="headerlink" title="warp的资源划分(resource partition)"></a>warp的资源划分(resource partition)</h4><p>一个warp的context包括三个部分：</p>
<ol>
<li>程序计数器(program counter)</li>
<li>寄存器(register)</li>
<li>共享内存(shared memory)</li>
</ol>
<p>每个SM有一个32位register集合放在register file中，还有固定数量的shared memory，这些资源都被thread瓜分了，由于资源是有限的，所以，如果thread数量比较多，那么每个thread占用资源就比较少，反之如果thread数量较少，每个thread占用资源就较多，这需要根据自己的需求作出一个平衡。资源限制了驻留在SM中blcok的数量，不同的GPU，register和shared memory的数量也不同。如果没有足够的资源，kernel的启动就会失败。当一个block获得足够多的资源时，就成为active block。block中的warp就称为active warp。SM中的warp调度器每个cycle会挑选active warp 送去执行。active warp又可以被分为3类：</p>
<ol>
<li>选中态 selected warp；</li>
<li>挂起态 stalled warp；</li>
<li>就绪态 eligible warp；</li>
</ol>
<p>warp执行有两个条件：</p>
<ul>
<li><em>32个CUDA core有空</em></li>
<li><em>当所有当前指令的参数都准备就绪</em></li>
</ul>
<p>在同一个context中切换是没有消耗的，在SM内部硬件能够检测到已经准备就绪、等待执行下一条指令的warp，其所需的资源以及数据依赖关系已经解决。SM基于内部优先级调度，从就绪warp池中选择一个warp，将其发送到SIMD核心上。TLP(thread level parallel)的思想就是给调度器提供尽可能多的线程以供选择，进而使性能损失的可能性最小化。CUDA编程中应该重视对计算资源的分配，这些资源限制了active warp的数量。因此为了最大化GPU利用率，我们必须最大化active warp的数目。</p>
<p>NVIDIA 提供了CUDA占用率计算器来帮助我们选择执行配置。</p>
<h4 id="通常的执行配置-网格的线程块数量-启发式规则包括"><a href="#通常的执行配置-网格的线程块数量-启发式规则包括" class="headerlink" title="通常的执行配置(网格的线程块数量)启发式规则包括"></a>通常的执行配置(网格的线程块数量)启发式规则包括</h4><ul>
<li>指定比SM数量多的线程块，保证所有的SM至少会分得一个Block执行。这是下线，指定比SM数量少的线程块很明显不能利用所有的GPU资源。</li>
<li>为了在小规模问题上充分运用kernel的异步执行，开发者会故意不完全使用GPU。GPU能够利用kernel的并行执行，在空闲的SM上执行其他kernel函数的线程块来提升性能。这些GPU能够加速以下程序：包含多个kernel函数，这些kernel函数尺寸太小，以至于无法使用PU上所有SM，而将其传输到CPU处理会太费时间。</li>
<li>为每个SM指定多个线程块，以便于在SM内部并行执行；</li>
<li>将block的数量选定为GPU内SM数量的整数倍，完全利用所有的SM，这种方法确保了所有SM负载均衡；</li>
<li>不处于__syncthreads的block会保持硬件繁忙</li>
<li>能够执行的block数量取决于SM中可使用的资源，包括寄存器，共享内存空间。</li>
<li>如果可能，为每个grid指定一个很大的block数量，这样做有利于程序运行在不同的GPU上，这将使SM满载分配给它的线程块。</li>
</ul>
<h4 id="指令级并行ILP-instruction-level-parallel-：高性能低占用率"><a href="#指令级并行ILP-instruction-level-parallel-：高性能低占用率" class="headerlink" title="指令级并行ILP(instruction level parallel)：高性能低占用率"></a>指令级并行ILP(instruction level parallel)：高性能低占用率</h4><p>“指令级并行 ILP”的含义是：如果程序中相邻的一组指令是相互独立的，即不竞争同一个功能部件、不相互等待对方的运算结果、不访问同一个存储单元，那么它们就可以在处理器内部并行地执行。</p>
<p>上面提到的TLP通过尽可能使得SM占用率高来提升性能，然而高占用率不一定会转变为最佳应用性能。指令级并行在隐藏算数延迟中国也非常有效，它能以更少的线程保持SIMD核心忙碌，因此会消耗更少的资源，带来更少的开销。使用ILP的原因很简单：<strong>使用较少的线程意味着每个线程可以使用更多的寄存器，寄存器是很珍贵的资源，是唯一足够快速并能够获得GPU峰值性能的存储器</strong>。寄存器存储于其他内存之间的贷款差距越悬殊，就应该有越多的数据存储在寄存器中，以获得较高的性能。</p>
<p>使用少量的线程有以下好处：</p>
<ol>
<li>能为每个线程分配多一点寄存器防止寄存器溢出；</li>
<li>使用少量的线程对使用shared memory的函数有利，这样做减少了对共享内存的访问，并允许线程内部的数据重用；</li>
<li>减少了GPU对每个线程所进行必要处理所需的开销；</li>
</ol>
<h3 id="为了提高应用的并行性，需要考虑如下几点"><a href="#为了提高应用的并行性，需要考虑如下几点" class="headerlink" title="为了提高应用的并行性，需要考虑如下几点"></a>为了提高应用的并行性，需要考虑如下几点</h3><p>Little(利特尔)法则：在一个稳定的系统中，长时间观察到的平均顾客数量L，等于，长时间观察到的有效到达速率λ与平均每个顾客在系统中花费的时间之乘积，即L &#x3D; λW。在理解存储器层次结构时有重要用途。推广到多处理器系统，little法则可以表达为:<br><em><strong>Concurrency &#x3D; bandwidth * latency</strong></em>.其中concurrency表示总的系统并行度，bandwidth表示总的存储带宽。</p>
<ul>
<li>寄存器   约为8TB&#x2F;s</li>
<li>共享内存 约为1.6TB&#x2F;s</li>
<li>全局内存 约为177GB&#x2F;s</li>
</ul>
<p>从TLP角度来看，little法则表明运行时的存储操作数量N是到达率λ和内存延迟的乘积。其中到达率是IPC(期望的指令速率)与加载指令密度的乘积。也就是说，当加入额外的线程并在同一硬件上多路复用时，可以隐藏很大的延迟。</p>
<p>从ILP角度来看，独立的访存事件能够被看成批处理(ILP合并提交的内存操作)<br>N&#x3D;λL-B,其中B是合并的独立加载指令的数量。</p>
<p>为了提高应用的并行性，需要考虑如下几点：</p>
<ul>
<li>提升占用率</li>
<li>使用nvcc命令行选项 -maxrregcount 最大化可用寄存器，或者在Kernel函数声明时让编译器使用 <strong>launch_bounds</strong> 给每个kernel函数分配额外的寄存器；</li>
<li>调整线程块的维度以最好的利用SM处理器warp调度器</li>
<li>修改代码以利用ILP使得每个线程处理多个元素，进行指令级并行；</li>
<li>不要在一个功能单元上出现瓶颈，从而导致其他单元停滞</li>
<li>不要把工作都放到一个kernel代码中：1、尝试创建多个小的线程块，使其操作(例如阵型，浮点型，内存以及SFU)密度均匀分布。2、不要将相同类型的操作聚集到kernel函数的同一部分，这样回使得SM负载不均衡。因为每个SM可以执行不同的kernel，所以将kernel的粒度弄的小一点更有助于负载均衡，这里让我想到了那个向瓶子里装石头的故事，大石头装完了还有很多空隙，可以装小石头，当然如果都是沙子，那一定能更好的利用瓶子的空间，这里将kernel中的功能细分也是这个目的。</li>
</ul>
<h3 id="nvcc编译器"><a href="#nvcc编译器" class="headerlink" title="nvcc编译器"></a>nvcc编译器</h3><p>nvcc编译器为UNIX、Windows、Mac OS X 操作系统提供了通用的编译架构。CUDA的编译器为nvcc,nvcc将各种编译工具集成起来，这些编译工具实现了编译的不同阶段。nvcc的基本工作流是将device代码从host代码中分离出来，然后将其编译成二进制或者cubin工程。在执行过程中，将忽略host代码，而将device代码加载并通过CUDA的设备API来执行。CUDA源代码在编译器前端是基于c++语法的。host代码中能够全部支持C++，但是在device中只能支持c++中的C部分。在kernel中不允许有C++的类、继承以及在基本块中定义变量等语法。C++中的void类型指针不能在没有类型转化的前提下赋值给一个非void的指针。</p>
<h4 id="pragma-unroll-循环展开"><a href="#pragma-unroll-循环展开" class="headerlink" title="#pragma unroll 循环展开"></a>#pragma unroll 循环展开</h4><p>nvcc编译器提供了#pragma unroll预编译指令，用来将循环展开。<br>编译器在编译时会对循环进行展开，比如对一些循环次数比较少的循环：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">for(int i=0;i&lt;4;i++)</span><br><span class="line">    cout&lt;&lt;&quot;hello world&quot;&lt;&lt;endl;</span><br></pre></td></tr></table></figure>
<p>可以展开为：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">cout&lt;&lt;&quot;hello world&quot;&lt;&lt;endl;</span><br><span class="line"></span><br><span class="line">cout&lt;&lt;&quot;hello world&quot;&lt;&lt;endl;</span><br><span class="line"></span><br><span class="line">cout&lt;&lt;&quot;hello world&quot;&lt;&lt;endl;</span><br><span class="line"></span><br><span class="line">cout&lt;&lt;&quot;hello world&quot;&lt;&lt;endl;</span><br></pre></td></tr></table></figure>
<p>这样程序的运行效率会更好，当然，现在大多数编译器都会自动这样优化，而通过使用#pragma unroll命令就可以控制编译器的对循环的展开程度。<br>看下面这段代码</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">int main()</span><br><span class="line">&#123;</span><br><span class="line">    int a[100];</span><br><span class="line"></span><br><span class="line">#pragma unroll 4</span><br><span class="line"></span><br><span class="line">    for(int i=0;i&lt;100;i++)</span><br><span class="line">    &#123;</span><br><span class="line">        a[i]=i;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    return 0;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>它的循环展开为</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">for(int i=0;i&lt;100;i+=4）</span><br><span class="line">&#123;</span><br><span class="line">    a[i]=i;</span><br><span class="line"></span><br><span class="line">    a[i+1]=i+1;</span><br><span class="line"></span><br><span class="line">    a[i+2]=i+2;</span><br><span class="line"></span><br><span class="line">    a[i+3]=i+3;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>循环展开的优势：</p>
<ul>
<li>更少的动态指令数量，相同工作量需要更少的比较与分支操作；</li>
<li>更好的调度机会，更多的独立指令可以提高ILP并隐藏流水线与内存访问的延迟；</li>
<li>充分利用寄存器与存储层次结构的局部性，展开外层循环，合并内层循环；</li>
</ul>
<h4 id="nvcc常用的命令"><a href="#nvcc常用的命令" class="headerlink" title="nvcc常用的命令"></a>nvcc常用的命令</h4><ul>
<li><strong>-arch&#x3D;sm_20</strong>:为计算能力2.0的设备产生代码；</li>
<li><strong>-maxrregcount&#x3D;N</strong>:指定了每个文件内kernel函数最多能够使用的寄存器的数量；</li>
<li><strong><strong>launch_bounds</strong></strong>:限定符可以在kernel函数声明时使用，控制每个kernel函数使用的寄存器数量；</li>
<li><strong>–ptxas-options &#x3D; -v</strong>或者 <strong>-Xptxas&#x3D;-v</strong>:列出每个kernel函数的寄存器、共享内存、常量内存的使用情况；</li>
<li><strong>-use_fast_math</strong>:强制每个 **functionName()**调用变换为等价的本地硬件函数调用名 **__functionName()**。这个方法使得代码运行更快，代价是精度和准确度稍稍下降；</li>
</ul>
<h3 id="参考博客"><a href="#参考博客" class="headerlink" title="参考博客"></a>参考博客</h3><p><a target="_blank" rel="noopener" href="http://blog.163.com/wujiaxing009@126/blog/static/71988399201701224540201/">CUDA性能优化—-warp深度解析</a><br><a target="_blank" rel="noopener" href="http://blog.csdn.net/nothinglefttosay/article/details/44725497">#pragma unroll介绍</a></p>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta"><i class="fas fa-circle-user fa-fw"></i>Author: </span><span class="post-copyright-info"><a href="http://example.com">cleo</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta"><i class="fas fa-square-arrow-up-right fa-fw"></i>Link: </span><span class="post-copyright-info"><a href="http://example.com/2018/01/15/%E9%AB%98%E6%80%A7%E8%83%BDCUDA%E5%BA%94%E7%94%A8%E8%AE%BE%E8%AE%A1%E4%B8%8E%E5%BC%80%E5%8F%91%E2%80%94%E2%80%94%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0%EF%BC%88%E7%AC%AC%E5%9B%9B%E7%AB%A0%EF%BC%89/">http://example.com/2018/01/15/%E9%AB%98%E6%80%A7%E8%83%BDCUDA%E5%BA%94%E7%94%A8%E8%AE%BE%E8%AE%A1%E4%B8%8E%E5%BC%80%E5%8F%91%E2%80%94%E2%80%94%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0%EF%BC%88%E7%AC%AC%E5%9B%9B%E7%AB%A0%EF%BC%89/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta"><i class="fas fa-circle-exclamation fa-fw"></i>Copyright Notice: </span><span class="post-copyright-info">All articles on this blog are licensed under <a target="_blank" rel="noopener" href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0</a> unless otherwise stated.</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/CUDA/">CUDA</a><a class="post-meta__tags" href="/tags/%E9%AB%98%E6%80%A7%E8%83%BD%E8%AE%A1%E7%AE%97/">高性能计算</a></div><div class="post-share"><div class="social-share" data-image="/img/11111.jpg" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><a class="pagination-related" href="/2018/01/21/Dijkstras%E6%9C%80%E7%9F%AD%E8%B7%AF%E5%BE%84%E7%AE%97%E6%B3%95%E7%9A%84MPI%E5%92%8CCUDA%E5%AE%9E%E7%8E%B0/" title="Dijkstras最短路径算法的MPI和CUDA实现"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info"><div class="info-1"><div class="info-item-1">Previous</div><div class="info-item-2">Dijkstras最短路径算法的MPI和CUDA实现</div></div><div class="info-2"><div class="info-item-1">Dijkstras最短路径算法的MPI和CUDA实现 主要内容   dijkstra串行算法 算法并行性分析 MPI的dijkstra实现 CUDA的dijkstra实现 并行效率分析    dijkstra串行算法串行算法核心思想 引入一个辅助向量D，它的每个分量D[i]为源顶点v到其他顶点v[i]的路径长度。初始态为：如有从v到vi的路径，则D[i]为弧[v,vi]的权值；否则D[i]为无穷大。显然D[j] &#x3D; min{D[i]}为顶点v出发到其他顶点的一条最短路径的长度，其路径为（v，vj）。下一条最短路径长度要么是源顶点v直接到某一顶点vk的长度，即{v，vk}。要么是源顶点v经过顶点vj到某一顶点的长度，即{v，vj，vk}。假设S为已经求得最短路径的顶点的集合，下一条最短路径（设其终点为x），要么是弧{v， vx}，要么为中间只经过S中顶点而最后到达终点X的路径。在一般情况下，下一条最短路径的长度为：D[j] &#x3D; min{D[i] | vi 属于 V-S} 其中V为图顶点的集合， D[i]为弧{v， vi}的权值，或者为D[k]和弧{vk，...</div></div></div></a><a class="pagination-related" href="/2018/01/14/%E4%BC%8A%E5%88%A9%E8%AF%BA%E9%A6%99%E5%AE%BE%E5%A4%A7%E5%AD%A6%E9%AB%98%E6%80%A7%E8%83%BD%E5%B9%B6%E8%A1%8C%E8%AE%A1%E7%AE%971-2%E7%AC%94%E8%AE%B0/" title="伊利诺香宾大学高性能并行计算week1笔记"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-right"><div class="info-1"><div class="info-item-1">Next</div><div class="info-item-2">伊利诺香宾大学高性能并行计算week1笔记</div></div><div class="info-2"><div class="info-item-1">异构并行计算Heterogeneous_Parallel_Computing简介 主要内容   学习延迟设备(CPU)和吞吐设备(GPU)之间的主要区别 为什么越来越多的应用同时使用这两种设备      CPU与GPU的区别    CPU有更大的局部cache，GPU有相对小的cache和局部内存。 GPU有更多的寄存器，支持大量的线程。而CPU只有能够支持少量线程的寄存器。 GPU有更多的SIMD执行单元； CPU有复杂的控制器，CPU有简单的控制单元，但是有大量的线程需要管理    CPU特性：CPU延迟敏感，以减少延迟为目标   上图中的三个特性解释如下：  强大的ALU，减少操作延迟：ALU(算术逻辑单元)被设计的很强大，可以在几个时钟周期中进行数值计算。现在的CPU核心中，64位双精度浮点运算，加法运算、乘法运算只需要花费1-3个时钟周期。...</div></div></div></a></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>Related Articles</span></div><div class="relatedPosts-list"><a class="pagination-related" href="/2018/01/21/Dijkstras%E6%9C%80%E7%9F%AD%E8%B7%AF%E5%BE%84%E7%AE%97%E6%B3%95%E7%9A%84MPI%E5%92%8CCUDA%E5%AE%9E%E7%8E%B0/" title="Dijkstras最短路径算法的MPI和CUDA实现"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2018-01-21</div><div class="info-item-2">Dijkstras最短路径算法的MPI和CUDA实现</div></div><div class="info-2"><div class="info-item-1">Dijkstras最短路径算法的MPI和CUDA实现 主要内容   dijkstra串行算法 算法并行性分析 MPI的dijkstra实现 CUDA的dijkstra实现 并行效率分析    dijkstra串行算法串行算法核心思想 引入一个辅助向量D，它的每个分量D[i]为源顶点v到其他顶点v[i]的路径长度。初始态为：如有从v到vi的路径，则D[i]为弧[v,vi]的权值；否则D[i]为无穷大。显然D[j] &#x3D; min{D[i]}为顶点v出发到其他顶点的一条最短路径的长度，其路径为（v，vj）。下一条最短路径长度要么是源顶点v直接到某一顶点vk的长度，即{v，vk}。要么是源顶点v经过顶点vj到某一顶点的长度，即{v，vj，vk}。假设S为已经求得最短路径的顶点的集合，下一条最短路径（设其终点为x），要么是弧{v， vx}，要么为中间只经过S中顶点而最后到达终点X的路径。在一般情况下，下一条最短路径的长度为：D[j] &#x3D; min{D[i] | vi 属于 V-S} 其中V为图顶点的集合， D[i]为弧{v， vi}的权值，或者为D[k]和弧{vk，...</div></div></div></a><a class="pagination-related" href="/2018/01/14/%E4%BC%8A%E5%88%A9%E8%AF%BA%E9%A6%99%E5%AE%BE%E5%A4%A7%E5%AD%A6%E9%AB%98%E6%80%A7%E8%83%BD%E5%B9%B6%E8%A1%8C%E8%AE%A1%E7%AE%971-2%E7%AC%94%E8%AE%B0/" title="伊利诺香宾大学高性能并行计算week1笔记"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2018-01-14</div><div class="info-item-2">伊利诺香宾大学高性能并行计算week1笔记</div></div><div class="info-2"><div class="info-item-1">异构并行计算Heterogeneous_Parallel_Computing简介 主要内容   学习延迟设备(CPU)和吞吐设备(GPU)之间的主要区别 为什么越来越多的应用同时使用这两种设备      CPU与GPU的区别    CPU有更大的局部cache，GPU有相对小的cache和局部内存。 GPU有更多的寄存器，支持大量的线程。而CPU只有能够支持少量线程的寄存器。 GPU有更多的SIMD执行单元； CPU有复杂的控制器，CPU有简单的控制单元，但是有大量的线程需要管理    CPU特性：CPU延迟敏感，以减少延迟为目标   上图中的三个特性解释如下：  强大的ALU，减少操作延迟：ALU(算术逻辑单元)被设计的很强大，可以在几个时钟周期中进行数值计算。现在的CPU核心中，64位双精度浮点运算，加法运算、乘法运算只需要花费1-3个时钟周期。...</div></div></div></a><a class="pagination-related" href="/2018/01/13/%E9%AB%98%E6%80%A7%E8%83%BDCUDA%E5%BA%94%E7%94%A8%E8%AE%BE%E8%AE%A1%E4%B8%8E%E5%BC%80%E5%8F%91%E2%80%94%E2%80%94%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0%EF%BC%88%E7%AC%AC%E4%B8%80%E7%AB%A0%EF%BC%89/" title="高性能CUDA应用设计与开发——读书笔记（第一章）"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2018-01-13</div><div class="info-item-2">高性能CUDA应用设计与开发——读书笔记（第一章）</div></div><div class="info-2"><div class="info-item-1">第一章：CUDA入门与编程思想 主要内容   CUDA的一些基本概念 选用合适的CUDA API的准则 高性能GPU计算的三条准则 大O记号，以及数据传输的影响  CUDA的一些基本概念 用于CUDA的GPU是安装于主机系统Host中的独立设备 ...</div></div></div></a><a class="pagination-related" href="/2018/01/13/%E9%AB%98%E6%80%A7%E8%83%BDCUDA%E5%BA%94%E7%94%A8%E8%AE%BE%E8%AE%A1%E4%B8%8E%E5%BC%80%E5%8F%91%E2%80%94%E2%80%94%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0%EF%BC%88%E7%AC%AC%E4%BA%8C%E7%AB%A0%EF%BC%89/" title="高性能CUDA应用设计与开发——读书笔记（第二章）"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2018-01-13</div><div class="info-item-2">高性能CUDA应用设计与开发——读书笔记（第二章）</div></div><div class="info-2"><div class="info-item-1">第二章：CUDA在机器学习与优化中的应用 主要内容   精通CUDA的编程者应该如何为建模与数据挖掘做出巨大贡献 机器学习技术，以及XOR问题对于计算通用设备的重要性 C++仿函数    建模与模拟数学模型：对现实的抽象，用来对现实进行分析与预测。数值模拟：通过应用程序将数学模型映射到电脑上。  常用的两个建模方法： 基于第一性原理分析以及其他方法的人工推导模型     “第一性原理”是一个量子力学中的一个术语，意思是从头算，只采用最基本的事实，然后根据事实推论。   基于数据拟合的参数化模型     与人工推导模型相比，经过数据计算推导出的模型相对容易建立。许多现有方法可以建立精确的模型得到很好的推广。使用数据来拟合模型是一个代价高昂的计算过程，并行计算依靠于处理单元数量密切相关的因素来缩减运行时间。对显现非线性特征的系统进行建模时，因为非线性系统不会对输入刺激做出线性回应，这意味着不能仅仅根据输入或者系统刺激的线性组合来建模。  机器学习与神经网络  ...</div></div></div></a><a class="pagination-related" href="/2018/05/17/CUDA%E6%80%A7%E8%83%BD%E6%8C%87%E6%A0%87/" title="CUDA性能指标"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2018-05-17</div><div class="info-item-2">CUDA性能指标</div></div><div class="info-2"><div class="info-item-1">共享内存被分配在SM上的常驻线程块中，寄存器在线程中被分配。寄存器和共享内存是SM中的稀缺资源。CUDA将这些资源分配到SM中的所有常驻线程里。      参数 指令    观察线程束分化 nvprof –metrics branch_efficiency   获得分支和分化分支的事件计数器 nvprof –events branch,divergent_branch   检测活跃的线程束(一个内核的可实现占用率) nvprof –metrics achieved_occupacy   检测内核的内存读取效率 nvprof –metrics gld_throughput   检测全局加载效率 nvprof –metrics gld_efficiency   查看每个线程束上执行指令数量的平均值 nvprof –metrics inst_per_warp   查看因为同步占用的时间 nvprof –metrics stall_sync   检测内存加载&#x2F;存储效率指标 nvprof –metrics...</div></div></div></a><a class="pagination-related" href="/2019/01/23/Array-2D-CUDA%E4%BD%BF%E7%94%A8CUDA%E6%89%A9%E5%B1%95C-%E6%A8%A1%E6%9D%BF%E5%BA%93/" title="Array_2D_CUDA使用CUDA扩展C++模板库"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2019-01-23</div><div class="info-item-2">Array_2D_CUDA使用CUDA扩展C++模板库</div></div><div class="info-2"><div class="info-item-1">...</div></div></div></a></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info text-center"><div class="avatar-img"><img src="/img/11111.jpg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info-name">cleo</div><div class="author-info-description">From zero to hero</div><div class="site-data"><a href="/archives/"><div class="headline">Articles</div><div class="length-num">53</div></a><a href="/tags/"><div class="headline">Tags</div><div class="length-num">35</div></a><a href="/categories/"><div class="headline">Categories</div><div class="length-num">7</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/xxxxxx"><i class="fab fa-github"></i><span>Follow Me</span></a></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>Announcement</span></div><div class="announcement_content">This is my Blog</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>Contents</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%AC%AC%E5%9B%9B%E7%AB%A0%EF%BC%9ACUDA%E6%89%A7%E8%A1%8C%E6%A8%A1%E5%9E%8B"><span class="toc-number">1.</span> <span class="toc-text">第四章：CUDA执行模型</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%BA%BF%E7%A8%8B%E8%A7%92%E5%BA%A6%E7%9A%84GPU%E7%BC%96%E7%A8%8B"><span class="toc-number">1.1.</span> <span class="toc-text">线程角度的GPU编程</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%80%A7%E8%83%BD%E8%A7%92%E5%BA%A6%E7%9A%84GPU%E7%BC%96%E7%A8%8B"><span class="toc-number">1.2.</span> <span class="toc-text">性能角度的GPU编程</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%88%86%E6%94%AF%E9%A2%84%E6%B5%8B"><span class="toc-number">1.2.1.</span> <span class="toc-text">分支预测</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E9%81%BF%E5%85%8Dwarp%E5%88%86%E6%AD%A7-Warp-Divergence-%E7%9A%84%E5%87%86%E5%88%99"><span class="toc-number">1.2.2.</span> <span class="toc-text">避免warp分歧(Warp Divergence)的准则</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#warp%E7%9A%84%E8%B5%84%E6%BA%90%E5%88%92%E5%88%86-resource-partition"><span class="toc-number">1.2.3.</span> <span class="toc-text">warp的资源划分(resource partition)</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E9%80%9A%E5%B8%B8%E7%9A%84%E6%89%A7%E8%A1%8C%E9%85%8D%E7%BD%AE-%E7%BD%91%E6%A0%BC%E7%9A%84%E7%BA%BF%E7%A8%8B%E5%9D%97%E6%95%B0%E9%87%8F-%E5%90%AF%E5%8F%91%E5%BC%8F%E8%A7%84%E5%88%99%E5%8C%85%E6%8B%AC"><span class="toc-number">1.2.4.</span> <span class="toc-text">通常的执行配置(网格的线程块数量)启发式规则包括</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%8C%87%E4%BB%A4%E7%BA%A7%E5%B9%B6%E8%A1%8CILP-instruction-level-parallel-%EF%BC%9A%E9%AB%98%E6%80%A7%E8%83%BD%E4%BD%8E%E5%8D%A0%E7%94%A8%E7%8E%87"><span class="toc-number">1.2.5.</span> <span class="toc-text">指令级并行ILP(instruction level parallel)：高性能低占用率</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%B8%BA%E4%BA%86%E6%8F%90%E9%AB%98%E5%BA%94%E7%94%A8%E7%9A%84%E5%B9%B6%E8%A1%8C%E6%80%A7%EF%BC%8C%E9%9C%80%E8%A6%81%E8%80%83%E8%99%91%E5%A6%82%E4%B8%8B%E5%87%A0%E7%82%B9"><span class="toc-number">1.3.</span> <span class="toc-text">为了提高应用的并行性，需要考虑如下几点</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#nvcc%E7%BC%96%E8%AF%91%E5%99%A8"><span class="toc-number">1.4.</span> <span class="toc-text">nvcc编译器</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#pragma-unroll-%E5%BE%AA%E7%8E%AF%E5%B1%95%E5%BC%80"><span class="toc-number">1.4.1.</span> <span class="toc-text">#pragma unroll 循环展开</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#nvcc%E5%B8%B8%E7%94%A8%E7%9A%84%E5%91%BD%E4%BB%A4"><span class="toc-number">1.4.2.</span> <span class="toc-text">nvcc常用的命令</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%8F%82%E8%80%83%E5%8D%9A%E5%AE%A2"><span class="toc-number">1.5.</span> <span class="toc-text">参考博客</span></a></li></ol></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>Recent Posts</span></div><div class="aside-list"><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2024/11/10/DDIA%E7%AC%AC%E5%85%AD%E7%AB%A0%EF%BC%9A%E5%88%86%E5%8C%BA/" title="DDIA第六章：分区">DDIA第六章：分区</a><time datetime="2024-11-09T16:43:50.000Z" title="Created 2024-11-10 00:43:50">2024-11-10</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2024/11/09/%E5%BE%AE%E6%9C%8D%E5%8A%A1%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1%E7%9A%84%E6%80%9D%E8%80%83%E2%80%94%E2%80%94%E8%85%BE%E8%AE%AF%E8%AF%BE%E5%A0%82/" title="微服务架构设计的思考——腾讯课堂">微服务架构设计的思考——腾讯课堂</a><time datetime="2024-11-09T15:43:28.000Z" title="Created 2024-11-09 23:43:28">2024-11-09</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2024/04/08/%E8%AE%BE%E8%AE%A1%E4%B8%80%E4%B8%AA%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F%E4%B8%AD%E7%9A%84%E5%94%AF%E4%B8%80ID%E7%94%9F%E6%88%90%E5%99%A8/" title="设计一个分布式系统中的唯一ID生成器">设计一个分布式系统中的唯一ID生成器</a><time datetime="2024-04-08T13:55:11.000Z" title="Created 2024-04-08 21:55:11">2024-04-08</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2019/05/06/STL-sort%E5%87%BD%E6%95%B0%E5%AE%9E%E7%8E%B0%E8%AF%A6%E8%A7%A3/" title="STL sort函数实现详解">STL sort函数实现详解</a><time datetime="2019-05-06T07:39:25.000Z" title="Created 2019-05-06 15:39:25">2019-05-06</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2019/04/28/%E6%B5%85%E8%B0%88%E5%A4%9A%E8%8A%82%E7%82%B9CPU-GPU%E5%8D%8F%E5%90%8C%E8%AE%A1%E7%AE%97%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%E6%80%A7%E8%AE%BE%E8%AE%A1/" title="多节点CPU+GPU协同计算负载均衡">多节点CPU+GPU协同计算负载均衡</a><time datetime="2019-04-28T12:15:10.000Z" title="Created 2019-04-28 20:15:10">2019-04-28</time></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2019 - 2024 By cleo</div><div class="framework-info"><span>Framework </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>Theme </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="Reading Mode"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="Toggle Between Light and Dark Mode"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="Toggle Between Single-column and Double-column"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="Settings"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="Table of Contents"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="Back to Top"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><div class="js-pjax"></div><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></body></html>