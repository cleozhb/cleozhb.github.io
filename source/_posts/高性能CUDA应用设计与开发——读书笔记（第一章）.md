---
title: 高性能CUDA应用设计与开发——读书笔记（第一章）
date: 2018-01-13 15:36:10
categories: 读书笔记
tags: [高性能计算,CUDA]
---
## 第一章：CUDA入门与编程思想
> 主要内容

* CUDA的一些基本概念
* 选用合适的CUDA API的准则
* 高性能GPU计算的三条准则
* 大O记号，以及数据传输的影响
<!--more-->

### CUDA的一些基本概念

* **用于CUDA的GPU是安装于主机系统Host中的独立设备**
    GPGPU通过一个高速接口和主机系统相连，如PCIe(外设组件互连高速接口)总线。大多数工作站或者集群的节点可以装2-4个GPGPU。一个主机系统中能安装多少个GPGPU数量取决于该系统的物理能力，PCIe接口数量以及机箱的内部空间、电源负载、冷却系统等。每个GPU都是独立设备与主处理器独立运行，PCIe总线用来在设备间传输数据和命令。CUDA提供以下两种传输数据的方式：
    * 通过cudaMemcpu()进行显式数据传输；
    * 通过页锁定内存的映射进行隐式数据传输；这个接口维护了一段host区域和一段device区域，相互之间可以自动同步。一般都是数据载入host内存，然后映射入GPU，就可以在GPU上使用了，就像数据已经拷贝到GPU了一样。低端的GPU可以共享主机内存以节省成本和能源。使用映射锁定内存实现零拷贝。


* **GPGPU运行在一个和主处理器相隔离的存储空间中**
GPU都有自己的物理内存(例如RAM随机存取存储器，也叫主存，是与GPU直接交换数据的存储器，速度很快，但是比主机内存有更大的带宽)。GPU的带宽通常是CPU带宽的10-20倍。
cuda提供了统一虚拟地址(UVA),将主机和GPU的内存编入一个统一的地址空间，访问其他设备内存任然需要通过总线进行数据传输。UVA使得运行各个设备上的代码都可以通过同一个指针访问到其他设备中的数据。

* **CUDAKernel是可以在主机代码中调用，在CUDA设备上执行的子程序**
Kernel没有返回值，不算是个函数。通过__global__来定义，表示这个kernel可以由主处理器调用。

* **Kernel的调用是异步的，即主机仅仅把要执行的Kernel顺序提交给GPGPU,并不等待其执行完成，而是直接处理后面的其他任务**
在主机提交kernel一段时间后，kernel才开始在GPU上实际投入运行。这种异步调用使得kernel无法返回函数值。为了提高效率，可以创建一个由若干kernel组成的 **流水线**，使得GPU尽可能长时间的保持忙碌状态。所以还需要一些同步方式使得host确定kernel中多个kernel组成的刘淑娴合适处理完毕。CUDA提供了两种常用的同步方式：
    1. 显式调用cudaThreadSynchronize(),该函数使得主机进入阻塞状态，停止运行并等待所有已经提交的kernel执行完毕。
    2. 利用cudaMemory()实现阻塞式数据传输————在cudaMemory()内部调用了cudaThreadSynchronize().


流水线技术：可以理解为将一个重复的过程分解为若干个子过程，让每个子过程由专门的功能部件来实现。将多个处理过程在时间上错开，一次通过各功能段，这样内个子过程可以与其他子过程并行执行。

* **GPU上的基本运行单位是线程**
从软件角度讲，各个线程之间是相互隔离的，内个线程运行时都好像独占一个处理器，这个处理器有自己的寄存器和编号，同时运行于共享内存的环境中。然而，硬件决定了实际可以并发执行的线程的数量。位于GPU上的 *线程调度器*决定了某组线程何时运行，并且从软件角度快速在线程间切换，这些线程切换和调度对于开发者是透明的。一个kernel利用多个线程完成kernel中所规定的任务，这种方式称为线程级并行(TLP),有别于指令级并行(ILP).

* **GPU上最大可共享的内存区域称为全局内存**
全局内存是GB级别的RAM，多数的程序数据都存放在其中。全局内存是遵循 **整合访问**的硬件，即将多个内存传输整合为一个大的读取或者写入操作，达到数据进入内存最快传输速率。访问全局内存造成的延时是很高的，高达访问寄存器变量延时的600倍。别看全局内存的带宽很高(160-200G)但是相对于GPU每秒万亿次计算，还是不够的。 **所以GPU的数据重用才是达到高性能的关键。**


### 选用合适的CUDA API的准则

CUDA提供了多种API，编程时根据需要进行选择，在程序中可以自由混合使用这三种API。这些API从高层到低层包括：

1. 数据并行C++ Thrust API;
2. 可用于C或C++的Runtime API;
3. 可用于C或C++的Driver API;

Thrust 是一个类似于STL的针对CUDA的C++模板库。Trust提供与CUDA C完全兼容的接口，可以使我们高效地编写高性能并行程序。Thrust提供了丰富的数据并行算法，例如scan、sort、reduce等，可以简单快捷地构成复杂算法，并使得代码获得更高的可读性。使用这些高度抽象的方法来表达计算，可以隐藏细节，并且Trust会自动选择最有效率的算法实现。因此，程序员得以快速构建CUDA程序，并能够获得极高的稳定性和性能与精度。thrust依赖于Runtime API，正确使用C++模板将生成仿函数(或称仿函数对象)。仿函数(functor)，就是使一个类的使用看上去象一个函数。其实现就是类中实现一个operator()，这个类就有了类似函数的行为，就是一个仿函数类了。

CUDA程序可以在多种高级语言中使用(python,Java,FORTRAN).Thrust API属于高层API，在一定成功度上存在限制，就是它们将软件开发和硬件相隔离，无法发挥出硬件全部的性能。但是提供了许多现有的功能，对于开发者很方便，具有较高的可维护性。当编程者需要通过代码改进获得较好的性能时，或者想使用一些底层功能来更好的支持所开发的程序时，需要选用一些低级的接口。CUDA Runtime API在特定情况下更加简洁易读，且相当高效，最底层的是Driver API，它提供了更加细致的控制。底层的API需要调用更多的函数，指定更多的参数，且需要检查运行时错误和代码兼容性的问题。

### 高性能GPU计算的三条准则
1. 将数据放入并始终存储于GPU
2. 给GPU足够多的任务
3. 注重GPU上数据的重用，避免带宽的限制

### 大O记号，以及数据传输的影响
大O记号是一种表达问题尺寸增长对算法资源消耗的影响的一种常用方法，它可以方便的表示出不同输入参数下函数对处理器或者内存的资源消耗。在数据结构中我们的大O表示法用来描述一个函数的最差执行时间。

* O(1)消耗的资源固定，具有固定的执行时间或者空间。
* O(n)消耗资源随输入数据的尺寸线性增长。
* O(n2)性能和输入数据尺寸的平方成比例。

### 总结
牢记amdahl定律，最小化串行瓶颈，挖掘任务并行性与数据并行性。理解大O记号在算法设计中的意义，并努力寻找具有更小复杂度的代替算法。尝试组合多种GPU操作以获取最高的计算密度，并将PCIe总线数据传输的影响最小化。
